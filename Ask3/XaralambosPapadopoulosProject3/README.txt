manager.c
=========
Το αρχείο manager.c περιέχει τον κώδικα του manager, ο οποίος φτιάχνει ένα συγκεκριμένο αριθμό παιδιών, στα οποία στέλνει urls για να γίνουν crawl και παίρνει πίσω τα αποτελέσματα. Ο κώδικας των παιδιών βρίσκεται στο αρχείο child.c. Η επικοινωνία του manager με τα παιδιά του γίνεται μέσω pipes. Ο manager τερματίζει όταν γίνουν crawl συγκεκριμένο αριθμό από urls, αφού πρώτα ειδοποιήσει σχετικά τα παιδιά του, σώσει τα αποτελέσματα σ' ένα αρχείο και τυπώσει τα στατιστικά. Τα urls που έχει να κάνει crawl ο manager αποθηκεύονται σε μια ουρά, υλοποιημένη με συνδεδεμένη λίστα (queue.c, queue.h). Για να μην γίνει crawl δυο φορές το ίδιο url, γίνεται χρίση hashtable (hashtable.c, hashtable.h) ο οποίος χρησιμοποιεί μονά συνδεδεμένες λίστες για την αντιμετώπιση των colisions. Για να γνωρίζει ανα πάσα στιγμή ο manager ποιά παιδιά δουλεύουν και ποιά όχι και για να συγκεντρώνει αποτελέσματα με την ίδια σειρά με την οποία ανάθεσε τις δουλειές, χρησιμοποιεί δύο ουρές, υλοποιημένες με πίνακα. Η μία αποθηκεύει τα παιδιά που δουλεύουν και η άλλη τα παιδιά που κάθονται. Τέλος για να εκτυπώνονται ταξινομημένα αλφαριθμητικά τα αποτελέσματα χρησιμοποιείται δομή δυαδικού δέντρου (tree.c, tree.h).

main
----
Διαβάζει ορίσματα που δίνει ο χρήστης, αρχικοποιεί το hashtable με μέγεθος όσο τα συνολικά links που πρέπει να συγκεντρωθούν, ανοίγει το αρχείο εισόδου, αν έχει οριστεί και το αρχείο εξόδου και φορτώνει τα πρώτα urls στην ουρά. Μετά καλεί την συνάρτηση manage, η οποία οργανώνει όλη την δουλειά. Όταν αυτή τελειώσει, κλείνει το αρχείο εξόδου και επιστρέφει 0 αν όλα έχουν πάει καλά, αλλιώς -1 σε σφάλμα.

manage:
-------
Αρχικά ορίζει οτι θα αγνοεί το SIGRTMIN+2 όταν ειδοποιηθεί από ένα παιδί οτι αυτό τερμάτισε γιατί ούτως η άλλως θα πρέπει να περιμένει όλα τα παιδιά μέχρι να τελειώσουν, πριν να τερματίσει ο manager. Στη συνέχεια, δεσμεύει τη μνήμη που χρειάζεται για τα pids και τα pipes  των παιδιών καθώς και για τις δυο ουρές που δείχνουν ποιός είναι απασχολημένος και ποιός όχι. Δημιουργεί 2 pipes (4 άκρα) για να επικοινωνεί αμφίδρομα με τα παιδιά και τέλος δημιουργεί και τα παιδιά, τοποθετώντας τα αρχικά όλα στην ουρά που κάθονται. Μετά κλείνει τις άκρες των pipes που δεν χρειάζεται. Κατόπιν μέχρι να γίνει crawl ο αριθμός των url που ζήτησε ο χρήστης, στέλνει url στα παιδιά και συγκεντρώνει τα αποτελέσματα. Για τον σκοπό αυτό όσο υπάρχουν παιδιά που κάθονται και urls που δεν έχουν ερπετιαστεί ακόμα, διαλέγει το πρώτο παιδί και το 1ο url απο τις αντίστοιχες ουρές και αναθέτει στο παιδί δουλειά στέλνοντάς του το url μέσω pipe. Αμέσως μετά το παιδί τοποθετείται στην ουρά αυτών που δουλεύουν και ανατίθεται το επόμενο url στο επόμενο παιδι. Όταν δεν υπάρχουν πλέον παιδιά που να κάθονται ή καινούρια urls στην ουρά ο manager περιμένει να διαβάσει αποτελέσματα απο το πρώτο παιδί της ουράς με τα παιδιά που δουλεύουν. Μόλις λάβει τα αποτελέσματα, το παιδί επιστρέφεται στην ουρά που κάθονται και τα urls που επέστρεψε τα αποθηκεύει στο hashtable (με την loadUrl). Στην περίπτωση που δεν υπάρχουν ήδη μέσα, τα βάζει και στην ουρά των urls ωστε να ερπετιαστούν και αυτά με την σειρά τους. Τα στατιστικά που επέστρεψε το παιδί αποθηκεύονται στο δέντρο μαζί με το url απο το οποίο προέκυψαν. Όταν συμπληρωθει το απαιτούμενο πλήθος ειδοποιεί όλα τα παιδιά να τερματίσουν στέλνοντας τους το σήμα SIGRTMIN+1. Αφού τερματίσουν όλα τα παιδιά, γράφει τα αποτελέσματα που συγκεντρώθηκαν στο αρχείο εξόδου και τυπώνει τα στατιστικά για το ποιό ογκώδες url, το μέσο μέγεθος σελίδας και το μέσο χρόνο προσπέλασης.
Στο τέλος καθαρίζει όλες τις δομές και επιστρέφει 0 σε περίπτωση επιτυχειας, αλλιώς -1 για σφάλμα.

loadUrl:
--------
Φορτώνει ένα url για crawl. Δηλαδή προσπαθεί να το φορτώσει στο hashtable (γιατί ενδέχεται να υπάρχει ήδη μέσα) και στην περίπτωση που δεν υπάρχει το βάζει και στην ουρά. Επιστρέφει 0 αν όλα πάνε καλά, αλλιώς -1 σε περίπτωση σφάλματος.

cleanUp:
--------
Κλείνει και αποδεσμεύει όλα τα pipes, περιμένει όλα τα παιδιά να τερματίσουν και αποδεσμεύει τον πίνακα με τα pids τους και τέλος αποδεσμεύει τις ουρές αυτών που εργάζονται και που κάθονται.

﻿child.c:
========
Ένα παιδί με το που ξεκινήσει κλείνει τις άκρες των pipes που δεν χρειάζονται και εκτελεί την συνάρτηση work προκειμένου να εκτελέσει τις δουλειές που του αναθέτει ο πατέρας.

work:
-----
Η work παίρνει σαν ορίσματα ένα ρεύμα εισόδου και ένα ρεύμα εξόδου. Η πρώτη της δουλειά μόλις ξεκινήσει είναι να ορίσει την συνάρτηση signalHandler για το χειρισμό του σήματος SIGRTMIN+1. Μετά διαβάζει επαναληπτικά url απο το ρεύμα εισόδου, χρησιμοποιεί την crawl για να τα ερπετιάσει και γράφει τα αποτελέσματα στο ρεύμα εξόδου. Επιστρέφει 0 αν όλα πάνε καλά, διαφορετικά -1 σε περίπτωση σφάλματος.

crawl:
------
Η crawl παίρνει σαν όρισμα το url προς ερπετιασμό και επιστρέφει με αναφορά τα αποτελέσματα. Για να ερπετιάσει ένα url δημιουργεί ένα pipe απο το οποίο θα διαβάσει τα αποτελέσματα και ξεκινάει ένα παιδί το οποίο αφού κλείσει την άκρη διαβάσματος (pipeDesc[0]) ανακατευθύνει το stdout στην άρκη γραψίματος (pipeDesc[1]) (με την dup2) και εκτελεί μια wget (χρήση execlp) η οποία παίρνει σαν όρισμα το url και γράφει το αποτέλεσμα στο stdout, δηλαδή στην άκρη γραψίματος του pipe.
Μόλις η wget τερματίσει, η crawl διαβάζει τ' αποτελέσματα και τα παρσάρει εξάγοντας σταστιστικά και νέα url προς ερπετιασμό τα οποία αποθηκεύονται σε απλά συνδεδεμένη λίστα. Στο τέλος (αφού διάβασε όλο το buffer) κλείνει τα pipes και επιστρέφει την κατάσταση με την οποία τερμάτισε η wget.

urlInfo:
--------
Δέχεται ώς όρισμα ένα url και επιστρέφει με αναφορά ξεχωριστά το πρωτόκολλο, το host, το path και το είδος του αρχείου ή Directory, αν πρόκειται για κατάλογο. Επιστρέφει 0, αν όλα πάνει καλά, αλλιώς -1 σε περίπτωση σφάλματος.

freeList:
---------
Αποδεσμεύει την μονά συνδεδεμένη λίστα με urls που περιέχεται στο αποτέλεσμα της crawl.

signalHandler:
--------------
Η signalHandler αν λάβει σήμα SIGRTMIN+1, απαντάει με σήμα SIGRTMIN+2 στον manager και τερματίζει το παιδί.


hashtable.c:
============
hash_function:
--------------
Η συνάρτηση hash_function προσθέτει τον ascii κωδικό του κάθε χαρακτήρα του url που παίρνει ως είσοδο σε μία μεταβλητή και επιστρέφει το υπόλοιπο της μεταβλητής αυτής με το μέγεθος του hash_table.

initializeHashtable:
--------------------
Δεσμεύει ένα hashtable συγκεκριμμένου μεγέθους.

addHashtable:
-------------
Τοποθετεί urls μέσα στο hashtable. Αν το url υπάρχει ήδη, επιστρέφει 1, αλλιώς επιστρέφει 0 σε περίπτωση επιτυχίας ή -1 σε περίπτωση σφάλματος.

cleanupHashtable:
-----------------
Αποδεσμεύει το hashtable.

queue.c
=======
addQueue:
---------
Προσθέτει urls στο τέλος μιας δομής ουράς. Επιστρέφει -1 σε περίπτωση σφάλματος και 0 αν όλα πάνε μια χαρά.

removeQueue:
------------
Αφαιρεί ένα url από την αρχή της ουράς και το επιστρέφει. Αν η ουρά είναι άδεια επιστρέφει NULL.

tree.c
=======
addTree:
--------
Εισάγει στατιστικά στο δέντρο αποτελεσμάτων, χρησιμοποιώντας την αναδρομηκή συνάρτηση _addTree. Επιστρέφει 0 αν τοποθετήθηκε σωστά στο δέντρο το νέο url με τα άλλα αποτελέσματά του, -1 σε περίπτωση που κάποιο url υπάρχει ήδη μέσα στο δέντρο.

printTree:
----------
Τυπώνει τα περιεχόμενα του δέντρου ταξινομημένα αλφαριθμητικά, χρησιμοποιώντας την αναδρομική συνάρτηση _printTree.
